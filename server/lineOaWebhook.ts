import { Request, Response } from "express";
import OpenAI from "openai";
import { storage } from "./storage";
import { db } from "./db";
import { sql } from "drizzle-orm";
import crypto from "crypto";
import { LineImageService } from "./lineImageService";
import { GuardrailsService, GuardrailConfig } from "./services/guardrails";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface LineMessage {
  type: string;
  id: string;
  text?: string;
  // Image message
  contentProvider?: {
    type: string;
  };
  // Sticker message
  packageId?: string;
  stickerId?: string;
}

interface LineEvent {
  type: string;
  message?: LineMessage;
  replyToken?: string;
  source: {
    userId: string;
    type: string;
  };
}

interface LineWebhookBody {
  destination: string;
  events: LineEvent[];
}

// Verify Line signature
function verifyLineSignature(
  body: string,
  signature: string,
  channelSecret: string,
): boolean {
  const hash = crypto
    .createHmac("sha256", channelSecret)
    .update(body)
    .digest("base64");

  return hash === signature;
}

// Send reply message to Line
async function sendLineReply(
  replyToken: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        replyToken,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      console.error("‚ùå Line API Error:", await response.text());
      return false;
    }

    console.log("‚úÖ Line reply sent successfully");
    return true;
  } catch (error) {
    console.error("üí• Error sending Line reply:", error);
    return false;
  }
}

// Send push message to Line user (for Human Agent messages)
export async function sendLinePushMessage(
  userId: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/push", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        to: userId,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Line Push API Error:", errorText);
      return false;
    }

    console.log("‚úÖ Line push message sent successfully to:", userId);
    return true;
  } catch (error) {
    console.error("üí• Error sending Line push message:", error);
    return false;
  }
}

// Send image message to Line user (for Human Agent images)
export async function sendLineImageMessage(
  userId: string,
  imageUrl: string,
  channelAccessToken: string,
  captionText?: string,
) {
  try {
    // Convert relative URL to absolute URL for Line API
    const protocol = 'https:';
    const host = process.env.REPLIT_DOMAINS || 'localhost:5000';
    const absoluteImageUrl = `${protocol}//${host}${imageUrl}`;
    
    console.log('üì∏ Sending Line image message:', {
      userId,
      absoluteImageUrl,
      captionText
    });

    const messages: any[] = [
      {
        type: "image",
        originalContentUrl: absoluteImageUrl,
        previewImageUrl: absoluteImageUrl,
      }
    ];

    // Add caption text as separate message if provided
    if (captionText && captionText.trim()) {
      messages.push({
        type: "text",
        text: captionText,
      });
    }

    const response = await fetch("https://api.line.me/v2/bot/message/push", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        to: userId,
        messages: messages,
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Line Push Image API Error:", errorText);
      return false;
    }

    console.log("‚úÖ Line image message sent successfully to:", userId);
    return true;
  } catch (error) {
    console.error("üí• Error sending Line image message:", error);
    return false;
  }
}

// Get AI response using OpenAI with chat history
/**
 * Detect if user message is asking about image content
 */
function isImageRelatedQuery(message: string): boolean {
  const imageKeywords = [
    "‡∏£‡∏π‡∏õ",
    "‡∏£‡∏π‡∏õ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö",
    "‡∏†‡∏≤‡∏û",
    "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û",
    "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢",
    "image",
    "picture",
    "photo",
    "‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏∞‡πÑ‡∏£",
    "‡πÉ‡∏ô‡∏£‡∏π‡∏õ",
    "‡πÉ‡∏ô‡∏†‡∏≤‡∏û",
    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
    "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢",
    "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô",
    "‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ",
    "‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö",
    "what's in",
    "describe",
    "tell me about",
    "show",
    "picture",
    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
    "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î",
    "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
    "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô",
  ];

  const lowerMessage = message.toLowerCase();
  return imageKeywords.some((keyword) =>
    lowerMessage.includes(keyword.toLowerCase()),
  );
}

/**
 * Extract image analysis from system messages
 */
function extractImageAnalysis(messages: any[]): string {
  const systemMessages = messages.filter(
    (msg) =>
      msg.messageType === "system" &&
      msg.metadata?.messageType === "image_analysis",
  );

  if (systemMessages.length === 0) {
    return "";
  }

  let imageContext = "\n=== ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ===\n";

  // Get the most recent image analyses (last 3)
  const recentAnalyses = systemMessages.slice(-3);

  recentAnalyses.forEach((msg, index) => {
    const analysisContent = msg.content.replace("[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ", "");
    imageContext += `\n--- ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà ${index + 1} ---\n${analysisContent}\n`;
  });

  return imageContext;
}

// New function to get AI response without saving chat history (to prevent duplicates)
async function getAiResponseDirectly(
  userMessage: string,
  agentId: number,
  userId: string,
  channelType: string,
  channelId: string,
): Promise<string> {
  try {
    console.log(`üîç Debug: Getting agent ${agentId} for user ${userId}`);

    // Get agent configuration
    const agent = await storage.getAgentChatbot(agentId, userId);
    if (!agent) {
      console.log(`‚ùå Agent ${agentId} not found for user ${userId}`);
      return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";
    }

    console.log(`‚úÖ Found agent: ${agent.name}`);

    // Check if this is an image-related query
    const isImageQuery = isImageRelatedQuery(userMessage);
    console.log(`üñºÔ∏è Image-related query detected: ${isImageQuery}`);
    console.log(`üîç User message for analysis: "${userMessage}"`);

    // Get chat history if memory is enabled using new memory strategy
    let chatHistory: any[] = [];
    if (agent.memoryEnabled) {
      const memoryLimit = agent.memoryLimit || 10;
      console.log(
        `üìö Fetching chat history with memory strategy (limit: ${memoryLimit})`,
      );

      try {
        // Use new memory strategy that includes ALL message types
        chatHistory = await storage.getChatHistoryWithMemoryStrategy(
          userId,
          channelType,
          channelId,
          agentId,
          memoryLimit,
        );
        console.log(
          `üìù Found ${chatHistory.length} previous messages (all types included)`,
        );
      } catch (error) {
        console.error("‚ö†Ô∏è Error fetching chat history:", error);
        // Fallback to original method if new method fails
        try {
          chatHistory = await storage.getChatHistory(
            userId,
            channelType,
            channelId,
            agentId,
            memoryLimit,
          );
          console.log(
            `üìù Fallback: Found ${chatHistory.length} previous messages`,
          );
        } catch (fallbackError) {
          console.error("‚ö†Ô∏è Fallback error:", fallbackError);
        }
      }
    }

    // Get agent's documents for context with actual content
    const agentDocs = await storage.getAgentChatbotDocuments(agentId, userId);
    let contextPrompt = "";
    
    // Initialize documentContents in the correct scope
    const documentContents: string[] = [];

    if (agentDocs.length > 0) {
      console.log(`üìö Found ${agentDocs.length} documents for agent`);

      // Get actual document content for each linked document
      for (const agentDoc of agentDocs) {
        try {
          const document = await storage.getDocument(
            agentDoc.documentId,
            userId,
          );
          if (document && document.content) {
            // Limit content to first 2000 characters to avoid token limits
            const truncatedContent =
              document.content.length > 2000
                ? document.content.substring(0, 2000) + "..."
                : document.content;

            documentContents.push(
              `=== ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ${document.name} ===\n${truncatedContent}\n`,
            );
            console.log(
              `üìÑ Added document: ${document.name} (${document.content.length} chars)`,
            );
          }
        } catch (error) {
          console.error(
            `‚ùå Error fetching document ${agentDoc.documentId}:`,
            error,
          );
        }
      }

      if (documentContents.length > 0) {
        contextPrompt = `\n\n‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n${documentContents.join("\n")}
        
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢`;
        console.log(
          `‚úÖ Built context with ${documentContents.length} documents`,
        );
        console.log(
          `üìÑ Context prompt length: ${contextPrompt.length} characters`,
        );
      } else {
        console.log(`‚ö†Ô∏è No documents found or no content available`);
      }
    }

    // Always extract image analysis from recent chat history to maintain context
    let imageContext = "";
    if (chatHistory.length > 0) {
      imageContext = extractImageAnalysis(chatHistory);
      console.log(
        `üì∏ Image context extracted: ${imageContext.length} characters`,
      );
      if (imageContext) {
        console.log(
          `‚úÖ Image analysis found: ${imageContext.substring(0, 200)}...`,
        );
        
        // Debug: Show all system messages for analysis
        const systemMessages = chatHistory.filter(
          (msg) => msg.messageType === "system" && msg.metadata?.messageType === "image_analysis"
        );
        console.log(`üîç Found ${systemMessages.length} image analysis messages in chat history`);
        systemMessages.forEach((msg, index) => {
          console.log(`üìã Analysis ${index + 1}: ${msg.content.substring(0, 150)}... (ID: ${msg.metadata?.relatedImageMessageId})`);
        });
      } else {
        console.log(`‚ÑπÔ∏è No recent image analysis found in chat history`);
        
        // Debug: Show what system messages we have
        const allSystemMessages = chatHistory.filter((msg) => msg.messageType === "system");
        console.log(`üîç Total system messages in history: ${allSystemMessages.length}`);
        allSystemMessages.forEach((msg, index) => {
          console.log(`üìù System ${index + 1}: ${msg.content.substring(0, 100)}... (metadata: ${JSON.stringify(msg.metadata)})`);
        });
      }
    }

    // Build conversation messages including history
    const messages: any[] = [
      {
        role: "system",
        content: `${agent.systemPrompt}${contextPrompt}

‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç: ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏´‡∏£‡∏∑‡∏≠‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ ‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡∏±‡πâ‡∏ô‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏≠‡∏¢‡πà‡∏≤‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ "‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏î‡∏π‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ" ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÅ‡∏•‡πâ‡∏ß

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô
‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°`,
      },
    ];

    // Add chat history (exclude system messages from conversation flow)
    const userBotMessages = chatHistory.filter(
      (msg) => msg.messageType === "user" || msg.messageType === "assistant",
    );

    userBotMessages.forEach((msg) => {
      messages.push({
        role: msg.messageType === "user" ? "user" : "assistant",
        content: msg.content,
      });
    });

    // Add current user message with image context attached if available
    let enhancedUserMessage = userMessage;
    if (imageContext) {
      enhancedUserMessage = `${userMessage}

${imageContext}`;
      console.log(
        `üñºÔ∏è Enhanced user message with image context (${imageContext.length} chars)`,
      );
    }

    messages.push({
      role: "user",
      content: enhancedUserMessage,
    });

    console.log(
      `ü§ñ Sending ${messages.length} messages to OpenAI (including ${chatHistory.length} history messages)`,
    );

    // Initialize guardrails service if configured
    let guardrailsService: GuardrailsService | null = null;
    if (agent.guardrailsConfig) {
      guardrailsService = new GuardrailsService(agent.guardrailsConfig);
      console.log(`üõ°Ô∏è === GUARDRAILS SYSTEM ENABLED ===`);
      console.log(`üõ°Ô∏è Agent ID: ${agentId}, Agent Name: ${agent.name}`);
      console.log(`üõ°Ô∏è Guardrails Configuration:`, JSON.stringify(agent.guardrailsConfig, null, 2));
      
      // Show which guardrails features are enabled/disabled
      const features = [];
      if (agent.guardrailsConfig.contentFiltering?.enabled) {
        const contentSettings = [];
        if (agent.guardrailsConfig.contentFiltering.blockProfanity) contentSettings.push('Profanity');
        if (agent.guardrailsConfig.contentFiltering.blockHateSpeech) contentSettings.push('Hate Speech');
        if (agent.guardrailsConfig.contentFiltering.blockSexualContent) contentSettings.push('Sexual Content');
        if (agent.guardrailsConfig.contentFiltering.blockViolence) contentSettings.push('Violence');
        features.push(`Content Filtering: ${contentSettings.join(', ')}`);
      }
      if (agent.guardrailsConfig.privacyProtection?.enabled) {
        const privacySettings = [];
        if (agent.guardrailsConfig.privacyProtection.blockPersonalInfo) privacySettings.push('Personal Info');
        if (agent.guardrailsConfig.privacyProtection.blockFinancialInfo) privacySettings.push('Financial Info');
        if (agent.guardrailsConfig.privacyProtection.blockHealthInfo) privacySettings.push('Health Info');
        if (agent.guardrailsConfig.privacyProtection.maskPhoneNumbers) privacySettings.push('Phone Masking');
        if (agent.guardrailsConfig.privacyProtection.maskEmails) privacySettings.push('Email Masking');
        features.push(`Privacy Protection: ${privacySettings.join(', ')}`);
      }
      if (agent.guardrailsConfig.toxicityPrevention?.enabled) {
        features.push(`Toxicity Prevention: Threshold ${agent.guardrailsConfig.toxicityPrevention.toxicityThreshold}`);
      }
      if (agent.guardrailsConfig.responseQuality?.enabled) {
        features.push(`Response Quality: ${agent.guardrailsConfig.responseQuality.minResponseLength}-${agent.guardrailsConfig.responseQuality.maxResponseLength} chars`);
      }
      if (agent.guardrailsConfig.topicControl?.enabled) {
        features.push(`Topic Control: ${agent.guardrailsConfig.topicControl.strictMode ? 'Strict' : 'Lenient'} mode`);
      }
      if (agent.guardrailsConfig.businessContext?.enabled) {
        features.push(`Business Context: Professional tone required`);
      }
      
      console.log(`üõ°Ô∏è Active Features: ${features.join(' | ')}`);
      console.log(`üõ°Ô∏è === END GUARDRAILS INITIALIZATION ===`);
    } else {
      console.log(`üõ°Ô∏è Guardrails: DISABLED (no configuration found)`);
    }

    // Validate user input with guardrails
    if (guardrailsService) {
      console.log(`üîç === STARTING INPUT VALIDATION ===`);
      console.log(`üìù Original User Message: "${enhancedUserMessage}"`);
      
      const inputValidation = await guardrailsService.evaluateInput(enhancedUserMessage, {
        documents: documentContents,
        agent: agent
      });
      
      console.log(`üìä Input Validation Summary:`);
      console.log(`   ‚úì Allowed: ${inputValidation.allowed}`);
      console.log(`   ‚úì Confidence: ${inputValidation.confidence}`);
      console.log(`   ‚úì Triggered Rules: ${inputValidation.triggeredRules.join(', ') || 'None'}`);
      console.log(`   ‚úì Reason: ${inputValidation.reason || 'No issues found'}`);
      
      if (!inputValidation.allowed) {
        console.log(`üö´ === INPUT BLOCKED BY GUARDRAILS ===`);
        console.log(`üö´ Blocking Reason: ${inputValidation.reason}`);
        console.log(`üö´ Triggered Rules: ${inputValidation.triggeredRules.join(', ')}`);
        const suggestions = inputValidation.suggestions?.join(' ') || '';
        const blockedMessage = `‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ ${inputValidation.reason ? `(${inputValidation.reason})` : ''} ${suggestions}`;
        console.log(`üö´ Returning blocked message: "${blockedMessage}"`);
        return blockedMessage;
      }
      
      // Use modified content if privacy protection applied masking
      if (inputValidation.modifiedContent) {
        console.log(`üîí User input modified for privacy protection`);
        console.log(`üîí Original: "${enhancedUserMessage}"`);
        console.log(`üîí Modified: "${inputValidation.modifiedContent}"`);
        enhancedUserMessage = inputValidation.modifiedContent;
      }
      
      console.log(`‚úÖ INPUT VALIDATION PASSED - Proceeding to OpenAI`);
    } else {
      console.log(`‚è≠Ô∏è Skipping input validation - Guardrails disabled`);
    }

    // Debug: Log the complete system prompt for verification
    console.log("\n=== üîç DEBUG: Complete System Prompt ===");
    console.log(messages[0].content);
    console.log("=== End System Prompt ===\n");

    // Debug: Log user message
    console.log(`üìù User Message: "${userMessage}"`);

    // Debug: Log total prompt length
    const totalTokens = messages.reduce(
      (sum, msg) => sum + msg.content.length,
      0,
    );
    console.log(`üìä Total prompt length: ${totalTokens} characters`);

    const response = await openai.chat.completions.create({
      model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
      messages: messages,
      max_tokens: 1000,
      temperature: 0.7,
    });

    let aiResponse =
      response.choices[0].message.content ||
      "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";

    // Validate AI output with guardrails
    if (guardrailsService) {
      console.log(`üîç === STARTING OUTPUT VALIDATION ===`);
      console.log(`ü§ñ Original AI Response: "${aiResponse}"`);
      
      const outputValidation = await guardrailsService.evaluateOutput(aiResponse, {
        documents: documentContents,
        agent: agent,
        userQuery: userMessage
      });
      
      console.log(`üìä Output Validation Summary:`);
      console.log(`   ‚úì Allowed: ${outputValidation.allowed}`);
      console.log(`   ‚úì Confidence: ${outputValidation.confidence}`);
      console.log(`   ‚úì Triggered Rules: ${outputValidation.triggeredRules.join(', ') || 'None'}`);
      console.log(`   ‚úì Reason: ${outputValidation.reason || 'No issues found'}`);
      
      if (!outputValidation.allowed) {
        console.log(`üö´ === OUTPUT BLOCKED BY GUARDRAILS ===`);
        console.log(`üö´ Blocking Reason: ${outputValidation.reason}`);
        console.log(`üö´ Triggered Rules: ${outputValidation.triggeredRules.join(', ')}`);
        const suggestions = outputValidation.suggestions?.join(' ') || '';
        const blockedMessage = `‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ ${outputValidation.reason ? `(${outputValidation.reason})` : ''} ${suggestions}`;
        console.log(`üö´ Original blocked response: "${aiResponse}"`);
        console.log(`üö´ Returning blocked message: "${blockedMessage}"`);
        aiResponse = blockedMessage;
      } else if (outputValidation.modifiedContent) {
        console.log(`üîí AI output modified for compliance`);
        console.log(`üîí Original: "${aiResponse}"`);
        console.log(`üîí Modified: "${outputValidation.modifiedContent}"`);
        aiResponse = outputValidation.modifiedContent;
      }
      
      console.log(`‚úÖ OUTPUT VALIDATION PASSED - Final response ready`);
      console.log(`üìù Final AI Response: "${aiResponse}"`);
    } else {
      console.log(`‚è≠Ô∏è Skipping output validation - Guardrails disabled`);
    }

    // NOTE: Chat history saving is now handled by the calling function to prevent duplicates
    console.log(
      `ü§ñ Generated AI response for user ${userId} (${aiResponse.length} characters)`,
    );

    return aiResponse;
  } catch (error) {
    console.error("üí• Error getting AI response:", error);
    return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á";
  }
}

// Store processed message IDs to prevent duplicates with timestamp for cleanup
const processedMessageIds = new Map<string, number>();

// Clean up old processed message IDs (older than 1 hour)
const cleanupProcessedMessages = () => {
  const oneHourAgo = Date.now() - 60 * 60 * 1000;
  for (const [messageId, timestamp] of processedMessageIds.entries()) {
    if (timestamp < oneHourAgo) {
      processedMessageIds.delete(messageId);
    }
  }
};

// Schedule cleanup every 30 minutes
setInterval(cleanupProcessedMessages, 30 * 60 * 1000);

// Main webhook handler
export async function handleLineWebhook(req: Request, res: Response) {
  try {
    const signature = req.headers["x-line-signature"] as string;
    const webhookBody: LineWebhookBody = req.body;
    const body = JSON.stringify(webhookBody);

    console.log("üîî Line webhook received");
    console.log("üìù Body:", body);

    // Find the Line OA integration by matching the destination (Channel ID)
    const destination = webhookBody.destination;
    console.log(
      "üîç Debug: Looking for integration with destination:",
      destination,
    );

    // Get all Line OA integrations to find the matching one
    const allIntegrations = await storage.getAllSocialIntegrations();
    console.log(
      "‚úÖ Found",
      allIntegrations.length,
      "total social integrations",
    );

    // In Line webhooks, the destination is the Bot's User ID, not Channel ID
    // First try to match by Bot User ID, then fall back to any active integration
    let lineIntegration = allIntegrations.find(
      (integration) =>
        integration.type === "lineoa" &&
        integration.isActive &&
        integration.botUserId === destination,
    );

    // If no exact match found by Bot User ID, try fallback to any active Line OA integration
    if (!lineIntegration) {
      lineIntegration = allIntegrations.find(
        (integration) => integration.type === "lineoa" && integration.isActive,
      );
      if (lineIntegration) {
        console.log(
          "üîß Using fallback matching - found active Line OA integration",
        );
        // Update the Bot User ID for future webhook calls using raw SQL
        try {
          await db.execute(sql`
            UPDATE social_integrations 
            SET bot_user_id = ${destination}, updated_at = NOW() 
            WHERE id = ${lineIntegration.id}
          `);
          console.log("‚úÖ Updated Bot User ID for future webhook calls");
        } catch (error) {
          console.log("‚ö†Ô∏è Could not update Bot User ID:", error);
        }
      }
    }

    if (!lineIntegration) {
      console.log(
        "‚ùå No active Line OA integration found for destination:",
        destination,
      );
      return res
        .status(404)
        .json({ error: "No active Line OA integration found" });
    }

    console.log(
      "‚úÖ Found matching Line OA integration for user:",
      lineIntegration.userId,
    );
    console.log(
      "üîë Debug: Channel Access Token available:",
      !!lineIntegration.channelAccessToken,
    );
    console.log(
      "üîç Debug: Integration object keys:",
      Object.keys(lineIntegration),
    );

    // Verify signature
    if (!verifyLineSignature(body, signature, lineIntegration.channelSecret!)) {
      console.log("‚ùå Invalid Line signature");
      return res.status(401).json({ error: "Invalid signature" });
    }

    // Process each event
    for (const event of webhookBody.events) {
      if (event.type === "message" && event.message) {
        const message = event.message;
        const replyToken = event.replyToken!;
        let userMessage = "";
        let messageMetadata: any = {};

        console.log("üì± Message type:", message.type);
        console.log("üë§ User ID:", event.source.userId);

        // Handle different message types
        if (message.type === "text") {
          userMessage = message.text!;
          console.log("üí¨ Text message:", userMessage);
        } else if (message.type === "image") {
          userMessage = "[‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û]";

          // For Line images, construct content URLs using messageId and Channel Access Token
          const originalContentUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content`;
          const previewImageUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content/preview`;

          messageMetadata = {
            messageType: "image",
            messageId: message.id,
            contentProvider: message.contentProvider,
            originalContentUrl,
            previewImageUrl,
          };
          console.log("üñºÔ∏è Image message received, ID:", message.id);
          console.log("üîó Image URLs:", {
            originalContentUrl,
            previewImageUrl,
          });
        } else if (message.type === "sticker") {
          userMessage = "[‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå]";
          messageMetadata = {
            messageType: "sticker",
            packageId: message.packageId,
            stickerId: message.stickerId,
          };
          console.log(
            "üòÄ Sticker message received, Package:",
            message.packageId,
            "Sticker:",
            message.stickerId,
          );
        } else {
          // Handle other message types (video, audio, location, etc.)
          userMessage = `[${message.type}]`;
          messageMetadata = {
            messageType: message.type,
            messageId: message.id,
          };
          console.log("üìé Other message type:", message.type);
        }

        // Check if this message has already been processed
        const messageId = message.id;
        if (processedMessageIds.has(messageId)) {
          console.log(`‚ö†Ô∏è Message ${messageId} already processed, skipping...`);
          continue;
        }

        // Mark message as processed with timestamp
        processedMessageIds.set(messageId, Date.now());
        console.log(`‚úÖ Processing new message ${messageId}`);

        // Save user message with metadata
        let chatHistoryId: number | null = null;
        try {
          const savedChatHistory = await storage.createChatHistory({
            userId: lineIntegration.userId,
            channelType: "lineoa",
            channelId: event.source.userId,
            agentId: lineIntegration.agentId!,
            messageType: "user",
            content: userMessage,
            metadata: messageMetadata,
          });
          chatHistoryId = savedChatHistory.id;
          console.log(
            "üíæ Saved user message with metadata, ID:",
            chatHistoryId,
          );
        } catch (error) {
          console.error("‚ö†Ô∏è Error saving user message:", error);
        }

        // Handle image messages with immediate acknowledgment
        if (message.type === "image" && lineIntegration.channelAccessToken) {
          console.log("üñºÔ∏è Image message detected - sending immediate acknowledgment");
          
          // 1. Send immediate acknowledgment
          await sendLineReply(
            replyToken,
            "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß ‡∏Ç‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ô‡∏∞‡∏Ñ‡∏∞",
            lineIntegration.channelAccessToken
          );
          
          // 2. Process image and get analysis
          if (chatHistoryId && lineIntegration.agentId) {
            console.log("üñºÔ∏è Starting image processing...");
            const imageService = LineImageService.getInstance();

            try {
              // Wait for image processing to complete
              await imageService.processImageMessage(
                message.id,
                lineIntegration.channelAccessToken,
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                chatHistoryId,
              );
              console.log("‚úÖ Image processing completed successfully");
              
              // Get the SPECIFIC image analysis for THIS message
              const updatedChatHistory = await storage.getChatHistory(
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                10 // Get more messages to find the right analysis
              );
              
              // Find the image analysis that corresponds to THIS specific message
              const imageAnalysisMessage = updatedChatHistory.find(msg => 
                msg.messageType === 'system' && 
                msg.metadata?.messageType === 'image_analysis' &&
                msg.metadata?.relatedImageMessageId === message.id
              );
              
              if (imageAnalysisMessage) {
                const imageAnalysisResult = imageAnalysisMessage.content.replace('[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ', '');
                console.log(`üîç Found specific image analysis for message ${message.id}: ${imageAnalysisResult.substring(0, 100)}...`);
                
                // 3. Generate AI response with image analysis
                const contextMessage = `‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤ ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:

${imageAnalysisResult}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠`;

                const aiResponse = await getAiResponseDirectly(
                  contextMessage,
                  lineIntegration.agentId,
                  lineIntegration.userId,
                  "lineoa",
                  event.source.userId,
                );
                
                // 4. Send follow-up message with AI analysis
                await sendLinePushMessage(
                  event.source.userId,
                  aiResponse,
                  lineIntegration.channelAccessToken
                );
                
                // Save the assistant response
                await storage.createChatHistory({
                  userId: lineIntegration.userId,
                  channelType: "lineoa",
                  channelId: event.source.userId,
                  agentId: lineIntegration.agentId,
                  messageType: "assistant",
                  content: aiResponse,
                  metadata: { relatedImageMessageId: message.id },
                });
                
                console.log("‚úÖ Image analysis response sent successfully");
                
              } else {
                console.log("‚ö†Ô∏è No specific image analysis found for this message");
                await sendLinePushMessage(
                  event.source.userId,
                  "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                  lineIntegration.channelAccessToken
                );
              }
              
            } catch (error) {
              console.error("‚ö†Ô∏è Error processing image message:", error);
              await sendLinePushMessage(
                event.source.userId,
                "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                lineIntegration.channelAccessToken
              );
            }
          }
          
          // Broadcast to WebSocket for real-time updates
          if (typeof (global as any).broadcastToAgentConsole === "function") {
            (global as any).broadcastToAgentConsole({
              type: 'new_message',
              data: {
                userId: lineIntegration.userId,
                channelType: "lineoa",
                channelId: event.source.userId,
                agentId: lineIntegration.agentId,
                userMessage: userMessage,
                aiResponse: "‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡πâ‡∏ß ‡∏Ç‡∏≠‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏±‡∏Å‡∏Ñ‡∏£‡∏π‡πà‡∏ô‡∏∞‡∏Ñ‡∏∞",
                timestamp: new Date().toISOString()
              }
            });
          }
          
          // Skip normal AI response processing for images
          continue;
        }

        // Get AI response with chat history (only for text messages or provide context for multimedia)
        if (lineIntegration.agentId) {
          let contextMessage = userMessage;
          
          if (message.type === "sticker") {
            contextMessage = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏°‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢";
          }

          // Get AI response WITHOUT saving history (it's already handled in getAiResponse)
          const aiResponse = await getAiResponseDirectly(
            contextMessage,
            lineIntegration.agentId,
            lineIntegration.userId,
            "lineoa",
            event.source.userId, // Use Line user ID as channel identifier
          );
          console.log("ü§ñ AI response:", aiResponse);

          // Save only the assistant response (user message already saved above)
          try {
            await storage.createChatHistory({
              userId: lineIntegration.userId,
              channelType: "lineoa",
              channelId: event.source.userId,
              agentId: lineIntegration.agentId,
              messageType: "assistant",
              content: aiResponse,
              metadata: {},
            });
            console.log("üíæ Saved AI response to chat history");

            // Broadcast new message to Agent Console via WebSocket
            if (typeof (global as any).broadcastToAgentConsole === "function") {
              (global as any).broadcastToAgentConsole({
                type: "new_message",
                data: {
                  userId: lineIntegration.userId,
                  channelType: "lineoa",
                  channelId: event.source.userId,
                  agentId: lineIntegration.agentId,
                  userMessage: contextMessage,
                  aiResponse,
                  timestamp: new Date().toISOString(),
                },
              });
              console.log("üì° Broadcasted new message to Agent Console");
            }
          } catch (error) {
            console.error("‚ö†Ô∏è Error saving AI response:", error);
          }

          // Send reply to Line using stored access token
          if (lineIntegration.channelAccessToken) {
            await sendLineReply(
              replyToken,
              aiResponse,
              lineIntegration.channelAccessToken,
            );
          } else {
            console.log(
              "‚ùå No channel access token available for Line integration",
            );
            await sendLineReply(
              replyToken,
              "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ access token ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
              lineIntegration.channelSecret!,
            );
          }
        } else {
          await sendLineReply(
            replyToken,
            "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI Agent ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
            lineIntegration.channelSecret!,
          );
        }
      }
    }

    res.status(200).json({ status: "ok" });
  } catch (error) {
    console.error("üí• Line webhook error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
}
