import { Request, Response } from "express";
import OpenAI from "openai";
import { storage } from "./storage";
import { db } from "./db";
import { sql } from "drizzle-orm";
import crypto from "crypto";
import { LineImageService } from "./lineImageService";

const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

interface LineMessage {
  type: string;
  id: string;
  text?: string;
  // Image message
  contentProvider?: {
    type: string;
  };
  // Sticker message
  packageId?: string;
  stickerId?: string;
}

interface LineEvent {
  type: string;
  message?: LineMessage;
  replyToken?: string;
  source: {
    userId: string;
    type: string;
  };
}

interface LineWebhookBody {
  destination: string;
  events: LineEvent[];
}

// Verify Line signature
function verifyLineSignature(
  body: string,
  signature: string,
  channelSecret: string,
): boolean {
  const hash = crypto
    .createHmac("sha256", channelSecret)
    .update(body)
    .digest("base64");

  return hash === signature;
}

// Send reply message to Line
async function sendLineReply(
  replyToken: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/reply", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        replyToken,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      console.error("‚ùå Line API Error:", await response.text());
      return false;
    }

    console.log("‚úÖ Line reply sent successfully");
    return true;
  } catch (error) {
    console.error("üí• Error sending Line reply:", error);
    return false;
  }
}

// Send push message to Line user (for Human Agent messages)
export async function sendLinePushMessage(
  userId: string,
  message: string,
  channelAccessToken: string,
) {
  try {
    const response = await fetch("https://api.line.me/v2/bot/message/push", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${channelAccessToken}`,
      },
      body: JSON.stringify({
        to: userId,
        messages: [
          {
            type: "text",
            text: message,
          },
        ],
      }),
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error("‚ùå Line Push API Error:", errorText);
      return false;
    }

    console.log("‚úÖ Line push message sent successfully to:", userId);
    return true;
  } catch (error) {
    console.error("üí• Error sending Line push message:", error);
    return false;
  }
}

// Get AI response using OpenAI with chat history
/**
 * Detect if user message is asking about image content
 */
function isImageRelatedQuery(message: string): boolean {
  const imageKeywords = [
    "‡∏£‡∏π‡∏õ",
    "‡∏£‡∏π‡∏õ‡∏≠‡∏∞‡πÑ‡∏£‡∏Ñ‡∏£‡∏±‡∏ö",
    "‡∏†‡∏≤‡∏û",
    "‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û",
    "‡∏†‡∏≤‡∏û‡∏ñ‡πà‡∏≤‡∏¢",
    "image",
    "picture",
    "photo",
    "‡πÄ‡∏´‡πá‡∏ô‡∏≠‡∏∞‡πÑ‡∏£",
    "‡πÉ‡∏ô‡∏£‡∏π‡∏õ",
    "‡πÉ‡∏ô‡∏†‡∏≤‡∏û",
    "‡∏≠‡∏ò‡∏¥‡∏ö‡∏≤‡∏¢",
    "‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢",
    "‡∏î‡∏π‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô",
    "‡∏£‡∏π‡∏õ‡∏ô‡∏µ‡πâ",
    "‡∏†‡∏≤‡∏û‡∏ô‡∏µ‡πâ",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á",
    "‡∏£‡∏π‡∏õ‡∏ó‡∏µ‡πà‡πÅ‡∏ô‡∏ö",
    "what's in",
    "describe",
    "tell me about",
    "show",
    "picture",
    "‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
    "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î",
    "‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤",
    "‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô",
  ];

  const lowerMessage = message.toLowerCase();
  return imageKeywords.some((keyword) =>
    lowerMessage.includes(keyword.toLowerCase()),
  );
}

/**
 * Extract image analysis from system messages
 */
function extractImageAnalysis(messages: any[]): string {
  const systemMessages = messages.filter(
    (msg) =>
      msg.messageType === "system" &&
      msg.metadata?.messageType === "image_analysis",
  );

  if (systemMessages.length === 0) {
    return "";
  }

  let imageContext = "\n=== ‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤ ===\n";

  // Get the most recent image analyses (last 3)
  const recentAnalyses = systemMessages.slice(-3);

  recentAnalyses.forEach((msg, index) => {
    const analysisContent = msg.content.replace("[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ", "");
    imageContext += `\n--- ‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà ${index + 1} ---\n${analysisContent}\n`;
  });

  return imageContext;
}

// New function to get AI response without saving chat history (to prevent duplicates)
async function getAiResponseDirectly(
  userMessage: string,
  agentId: number,
  userId: string,
  channelType: string,
  channelId: string,
): Promise<string> {
  try {
    console.log(`üîç Debug: Getting agent ${agentId} for user ${userId}`);

    // Get agent configuration
    const agent = await storage.getAgentChatbot(agentId, userId);
    if (!agent) {
      console.log(`‚ùå Agent ${agentId} not found for user ${userId}`);
      return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";
    }

    console.log(`‚úÖ Found agent: ${agent.name}`);

    // Check if this is an image-related query
    const isImageQuery = isImageRelatedQuery(userMessage);
    console.log(`üñºÔ∏è Image-related query detected: ${isImageQuery}`);
    console.log(`üîç User message for analysis: "${userMessage}"`);

    // Get chat history if memory is enabled using new memory strategy
    let chatHistory: any[] = [];
    if (agent.memoryEnabled) {
      const memoryLimit = agent.memoryLimit || 10;
      console.log(
        `üìö Fetching chat history with memory strategy (limit: ${memoryLimit})`,
      );

      try {
        // Use new memory strategy that includes ALL message types
        chatHistory = await storage.getChatHistoryWithMemoryStrategy(
          userId,
          channelType,
          channelId,
          agentId,
          memoryLimit,
        );
        console.log(
          `üìù Found ${chatHistory.length} previous messages (all types included)`,
        );
      } catch (error) {
        console.error("‚ö†Ô∏è Error fetching chat history:", error);
        // Fallback to original method if new method fails
        try {
          chatHistory = await storage.getChatHistory(
            userId,
            channelType,
            channelId,
            agentId,
            memoryLimit,
          );
          console.log(
            `üìù Fallback: Found ${chatHistory.length} previous messages`,
          );
        } catch (fallbackError) {
          console.error("‚ö†Ô∏è Fallback error:", fallbackError);
        }
      }
    }

    // Get agent's documents for context with actual content
    const agentDocs = await storage.getAgentChatbotDocuments(agentId, userId);
    let contextPrompt = "";

    if (agentDocs.length > 0) {
      console.log(`üìö Found ${agentDocs.length} documents for agent`);

      // Get actual document content for each linked document
      const documentContents: string[] = [];
      for (const agentDoc of agentDocs) {
        try {
          const document = await storage.getDocument(
            agentDoc.documentId,
            userId,
          );
          if (document && document.content) {
            // Limit content to first 2000 characters to avoid token limits
            const truncatedContent =
              document.content.length > 2000
                ? document.content.substring(0, 2000) + "..."
                : document.content;

            documentContents.push(
              `=== ‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£: ${document.name} ===\n${truncatedContent}\n`,
            );
            console.log(
              `üìÑ Added document: ${document.name} (${document.content.length} chars)`,
            );
          }
        } catch (error) {
          console.error(
            `‚ùå Error fetching document ${agentDoc.documentId}:`,
            error,
          );
        }
      }

      if (documentContents.length > 0) {
        contextPrompt = `\n\n‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°:\n${documentContents.join("\n")}
        
‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏ä‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Ç‡πâ‡∏≤‡∏á‡∏ï‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡∏∞‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡πâ‡∏ß‡∏¢`;
        console.log(
          `‚úÖ Built context with ${documentContents.length} documents`,
        );
        console.log(
          `üìÑ Context prompt length: ${contextPrompt.length} characters`,
        );
      } else {
        console.log(`‚ö†Ô∏è No documents found or no content available`);
      }
    }

    // Always extract image analysis from recent chat history to maintain context
    let imageContext = "";
    if (chatHistory.length > 0) {
      imageContext = extractImageAnalysis(chatHistory);
      console.log(
        `üì∏ Image context extracted: ${imageContext.length} characters`,
      );
      if (imageContext) {
        console.log(
          `‚úÖ Image analysis found: ${imageContext.substring(0, 100)}...`,
        );
      } else {
        console.log(`‚ÑπÔ∏è No recent image analysis found in chat history`);
      }
    }

    // Build conversation messages including history
    const messages: any[] = [
      {
        role: "system",
        content: `${agent.systemPrompt}${contextPrompt}

‡∏ï‡∏≠‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏ß‡πâ‡∏ô‡πÅ‡∏ï‡πà‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏à‡∏∞‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡∏≠‡∏∑‡πà‡∏ô
‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠ ‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå

‡∏Ñ‡∏∏‡∏ì‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡∏ó‡∏µ‡πà‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°`,
      },
    ];

    // Add chat history (exclude system messages from conversation flow)
    const userBotMessages = chatHistory.filter(
      (msg) => msg.messageType === "user" || msg.messageType === "assistant",
    );

    userBotMessages.forEach((msg) => {
      messages.push({
        role: msg.messageType === "user" ? "user" : "assistant",
        content: msg.content,
      });
    });

    // Add current user message with image context attached if available
    let enhancedUserMessage = userMessage;
    if (imageContext) {
      enhancedUserMessage = `${userMessage}

${imageContext}`;
      console.log(
        `üñºÔ∏è Enhanced user message with image context (${imageContext.length} chars)`,
      );
    }

    messages.push({
      role: "user",
      content: enhancedUserMessage,
    });

    console.log(
      `ü§ñ Sending ${messages.length} messages to OpenAI (including ${chatHistory.length} history messages)`,
    );

    // Debug: Log the complete system prompt for verification
    console.log("\n=== üîç DEBUG: Complete System Prompt ===");
    console.log(messages[0].content);
    console.log("=== End System Prompt ===\n");

    // Debug: Log user message
    console.log(`üìù User Message: "${userMessage}"`);

    // Debug: Log total prompt length
    const totalTokens = messages.reduce(
      (sum, msg) => sum + msg.content.length,
      0,
    );
    console.log(`üìä Total prompt length: ${totalTokens} characters`);

    const response = await openai.chat.completions.create({
      model: "gpt-4o", // the newest OpenAI model is "gpt-4o" which was released May 13, 2024. do not change this unless explicitly requested by the user
      messages: messages,
      max_tokens: 1000,
      temperature: 0.7,
    });

    const aiResponse =
      response.choices[0].message.content ||
      "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ";

    // NOTE: Chat history saving is now handled by the calling function to prevent duplicates
    console.log(
      `ü§ñ Generated AI response for user ${userId} (${aiResponse.length} characters)`,
    );

    return aiResponse;
  } catch (error) {
    console.error("üí• Error getting AI response:", error);
    return "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏•‡∏≠‡∏á‡πÉ‡∏´‡∏°‡πà‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á";
  }
}

// Store processed message IDs to prevent duplicates with timestamp for cleanup
const processedMessageIds = new Map<string, number>();

// Clean up old processed message IDs (older than 1 hour)
const cleanupProcessedMessages = () => {
  const oneHourAgo = Date.now() - 60 * 60 * 1000;
  for (const [messageId, timestamp] of processedMessageIds.entries()) {
    if (timestamp < oneHourAgo) {
      processedMessageIds.delete(messageId);
    }
  }
};

// Schedule cleanup every 30 minutes
setInterval(cleanupProcessedMessages, 30 * 60 * 1000);

// Main webhook handler
export async function handleLineWebhook(req: Request, res: Response) {
  try {
    const signature = req.headers["x-line-signature"] as string;
    const webhookBody: LineWebhookBody = req.body;
    const body = JSON.stringify(webhookBody);

    console.log("üîî Line webhook received");
    console.log("üìù Body:", body);

    // Find the Line OA integration by matching the destination (Channel ID)
    const destination = webhookBody.destination;
    console.log(
      "üîç Debug: Looking for integration with destination:",
      destination,
    );

    // Get all Line OA integrations to find the matching one
    const allIntegrations = await storage.getAllSocialIntegrations();
    console.log(
      "‚úÖ Found",
      allIntegrations.length,
      "total social integrations",
    );

    // In Line webhooks, the destination is the Bot's User ID, not Channel ID
    // First try to match by Bot User ID, then fall back to any active integration
    let lineIntegration = allIntegrations.find(
      (integration) =>
        integration.type === "lineoa" &&
        integration.isActive &&
        integration.botUserId === destination,
    );

    // If no exact match found by Bot User ID, try fallback to any active Line OA integration
    if (!lineIntegration) {
      lineIntegration = allIntegrations.find(
        (integration) => integration.type === "lineoa" && integration.isActive,
      );
      if (lineIntegration) {
        console.log(
          "üîß Using fallback matching - found active Line OA integration",
        );
        // Update the Bot User ID for future webhook calls using raw SQL
        try {
          await db.execute(sql`
            UPDATE social_integrations 
            SET bot_user_id = ${destination}, updated_at = NOW() 
            WHERE id = ${lineIntegration.id}
          `);
          console.log("‚úÖ Updated Bot User ID for future webhook calls");
        } catch (error) {
          console.log("‚ö†Ô∏è Could not update Bot User ID:", error);
        }
      }
    }

    if (!lineIntegration) {
      console.log(
        "‚ùå No active Line OA integration found for destination:",
        destination,
      );
      return res
        .status(404)
        .json({ error: "No active Line OA integration found" });
    }

    console.log(
      "‚úÖ Found matching Line OA integration for user:",
      lineIntegration.userId,
    );
    console.log(
      "üîë Debug: Channel Access Token available:",
      !!lineIntegration.channelAccessToken,
    );
    console.log(
      "üîç Debug: Integration object keys:",
      Object.keys(lineIntegration),
    );

    // Verify signature
    if (!verifyLineSignature(body, signature, lineIntegration.channelSecret!)) {
      console.log("‚ùå Invalid Line signature");
      return res.status(401).json({ error: "Invalid signature" });
    }

    // Process each event
    for (const event of webhookBody.events) {
      if (event.type === "message" && event.message) {
        const message = event.message;
        const replyToken = event.replyToken!;
        let userMessage = "";
        let messageMetadata: any = {};

        console.log("üì± Message type:", message.type);
        console.log("üë§ User ID:", event.source.userId);

        // Handle different message types
        if (message.type === "text") {
          userMessage = message.text!;
          console.log("üí¨ Text message:", userMessage);
        } else if (message.type === "image") {
          userMessage = "[‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û]";

          // For Line images, construct content URLs using messageId and Channel Access Token
          const originalContentUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content`;
          const previewImageUrl = `https://api-data.line.me/v2/bot/message/${message.id}/content/preview`;

          messageMetadata = {
            messageType: "image",
            messageId: message.id,
            contentProvider: message.contentProvider,
            originalContentUrl,
            previewImageUrl,
          };
          console.log("üñºÔ∏è Image message received, ID:", message.id);
          console.log("üîó Image URLs:", {
            originalContentUrl,
            previewImageUrl,
          });
        } else if (message.type === "sticker") {
          userMessage = "[‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå]";
          messageMetadata = {
            messageType: "sticker",
            packageId: message.packageId,
            stickerId: message.stickerId,
          };
          console.log(
            "üòÄ Sticker message received, Package:",
            message.packageId,
            "Sticker:",
            message.stickerId,
          );
        } else {
          // Handle other message types (video, audio, location, etc.)
          userMessage = `[${message.type}]`;
          messageMetadata = {
            messageType: message.type,
            messageId: message.id,
          };
          console.log("üìé Other message type:", message.type);
        }

        // Check if this message has already been processed
        const messageId = message.id;
        if (processedMessageIds.has(messageId)) {
          console.log(`‚ö†Ô∏è Message ${messageId} already processed, skipping...`);
          continue;
        }

        // Mark message as processed with timestamp
        processedMessageIds.set(messageId, Date.now());
        console.log(`‚úÖ Processing new message ${messageId}`);

        // Save user message with metadata
        let chatHistoryId: number | null = null;
        try {
          const savedChatHistory = await storage.createChatHistory({
            userId: lineIntegration.userId,
            channelType: "lineoa",
            channelId: event.source.userId,
            agentId: lineIntegration.agentId!,
            messageType: "user",
            content: userMessage,
            metadata: messageMetadata,
          });
          chatHistoryId = savedChatHistory.id;
          console.log(
            "üíæ Saved user message with metadata, ID:",
            chatHistoryId,
          );
        } catch (error) {
          console.error("‚ö†Ô∏è Error saving user message:", error);
        }

        // Get AI response with chat history (only for text messages or provide context for multimedia)
        if (lineIntegration.agentId) {
          let contextMessage = userMessage;
          let imageAnalysisResult = "";
          
          // Process image download and analysis SYNCHRONOUSLY if it's an image message
          if (
            message.type === "image" &&
            chatHistoryId &&
            lineIntegration.channelAccessToken
          ) {
            console.log("üñºÔ∏è Starting synchronous image processing...");
            const imageService = LineImageService.getInstance();

            try {
              // Wait for image processing to complete before proceeding
              await imageService.processImageMessage(
                message.id,
                lineIntegration.channelAccessToken,
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                chatHistoryId,
              );
              console.log("‚úÖ Image processing completed successfully");
              
              // Get the image analysis from the updated chat history
              const updatedChatHistory = await storage.getChatHistory(
                lineIntegration.userId,
                "lineoa",
                event.source.userId,
                lineIntegration.agentId!,
                5 // Get last 5 messages to find the image analysis
              );
              
              // Find the most recent image analysis
              const imageAnalysisMessage = updatedChatHistory.find(msg => 
                msg.messageType === 'system' && 
                msg.metadata?.messageType === 'image_analysis'
              );
              
              if (imageAnalysisMessage) {
                imageAnalysisResult = imageAnalysisMessage.content.replace('[‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û] ', '');
                console.log(`üîç Found image analysis: ${imageAnalysisResult.substring(0, 100)}...`);
                
                // Use image analysis as context for AI response
                contextMessage = `‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤ ‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û:

${imageAnalysisResult}

‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡πÉ‡∏´‡πâ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏™‡∏¥‡πà‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡πÉ‡∏ô‡∏£‡∏π‡∏õ ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢‡πÄ‡∏´‡∏•‡∏∑‡∏≠`;
              } else {
                contextMessage = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤ ‡πÅ‡∏ï‡πà‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÑ‡∏î‡πâ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏£‡∏±‡∏ö‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÅ‡∏•‡∏∞‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤ user ‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢";
              }
            } catch (error) {
              console.error("‚ö†Ô∏è Error processing image message:", error);
              contextMessage = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤ ‡πÅ‡∏ï‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢";
            }
          } else if (message.type === "sticker") {
            contextMessage = "‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏á‡∏™‡∏ï‡∏¥‡πä‡∏Å‡πÄ‡∏Å‡∏≠‡∏£‡πå‡∏°‡∏≤ ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏ï‡∏£‡πÅ‡∏•‡∏∞‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡πÉ‡∏´‡πâ‡∏ä‡πà‡∏ß‡∏¢";
          }

          // Get AI response WITHOUT saving history (it's already handled in getAiResponse)
          const aiResponse = await getAiResponseDirectly(
            contextMessage,
            lineIntegration.agentId,
            lineIntegration.userId,
            "lineoa",
            event.source.userId, // Use Line user ID as channel identifier
          );
          console.log("ü§ñ AI response:", aiResponse);

          // Save only the assistant response (user message already saved above)
          try {
            await storage.createChatHistory({
              userId: lineIntegration.userId,
              channelType: "lineoa",
              channelId: event.source.userId,
              agentId: lineIntegration.agentId,
              messageType: "assistant",
              content: aiResponse,
              metadata: {},
            });
            console.log("üíæ Saved AI response to chat history");

            // Broadcast new message to Agent Console via WebSocket
            if (typeof (global as any).broadcastToAgentConsole === "function") {
              (global as any).broadcastToAgentConsole({
                type: "new_message",
                data: {
                  userId: lineIntegration.userId,
                  channelType: "lineoa",
                  channelId: event.source.userId,
                  agentId: lineIntegration.agentId,
                  userMessage: contextMessage,
                  aiResponse,
                  timestamp: new Date().toISOString(),
                },
              });
              console.log("üì° Broadcasted new message to Agent Console");
            }
          } catch (error) {
            console.error("‚ö†Ô∏è Error saving AI response:", error);
          }

          // Send reply to Line using stored access token
          if (lineIntegration.channelAccessToken) {
            await sendLineReply(
              replyToken,
              aiResponse,
              lineIntegration.channelAccessToken,
            );
          } else {
            console.log(
              "‚ùå No channel access token available for Line integration",
            );
            await sendLineReply(
              replyToken,
              "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ access token ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
              lineIntegration.channelSecret!,
            );
          }
        } else {
          await sendLineReply(
            replyToken,
            "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢ ‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ö AI Agent ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏¥‡∏î‡∏ï‡πà‡∏≠‡∏ú‡∏π‡πâ‡∏î‡∏π‡πÅ‡∏•‡∏£‡∏∞‡∏ö‡∏ö",
            lineIntegration.channelSecret!,
          );
        }
      }
    }

    res.status(200).json({ status: "ok" });
  } catch (error) {
    console.error("üí• Line webhook error:", error);
    res.status(500).json({ error: "Internal server error" });
  }
}
